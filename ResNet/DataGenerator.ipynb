{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR='data'\n",
    "DIM=(512, 384)\n",
    "BATCH_SIZE=24\n",
    "NUM_EPOCHS=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53050 images belonging to 16 classes.\n",
      "Found 4814 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=1/12)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DIR,\n",
    "    target_size=DIM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    DIR,\n",
    "    target_size=DIM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 597.5714285714286,\n",
       " 1: 9.750582750582751,\n",
       " 2: 2.789906625166741,\n",
       " 3: 5.237479131886477,\n",
       " 4: 2.9751066856330013,\n",
       " 5: 2.574153846153846,\n",
       " 6: 66.04736842105264,\n",
       " 7: 4.90962441314554,\n",
       " 8: 3.4100543478260867,\n",
       " 9: 1568.625,\n",
       " 10: 1.0,\n",
       " 11: 2.441914769410391,\n",
       " 12: 1.7458263772954925,\n",
       " 13: 16.88963660834455,\n",
       " 14: 15.965648854961833,\n",
       " 15: 4.303497942386831}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_generator.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "    validation_data = validation_generator,\n",
    "    epochs=NUM_EPOCHS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
