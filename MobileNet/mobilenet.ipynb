{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkyVSLo23Oqm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmX2aIbj45Zj"
   },
   "outputs": [],
   "source": [
    "DIR = 'drive/My Drive/animals10/raw-img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MZfjGPX35UIS",
    "outputId": "a4d8f781-1a25-47d8-c9a4-a171a27ee975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20947 images belonging to 10 classes.\n",
      "Found 5232 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DIR,\n",
    "    target_size=(160, 160),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    DIR,\n",
    "    target_size=(160, 160),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BELrM3cC6NwJ",
    "outputId": "82d3f9fc-8430-4775-918f-f71aaca34f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(input_shape=(160, 160, 3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXuoRdcUGrKU"
   },
   "outputs": [],
   "source": [
    "global_average_layer = GlobalAveragePooling2D()\n",
    "prediction_layer = Dense(10, activation='softmax')\n",
    "model = Sequential([\n",
    "    base_model, \n",
    "    global_average_layer, \n",
    "    prediction_layer\n",
    "])\n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=RMSprop(lr=base_learning_rate),\n",
    "              loss=BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "GtPExzUE9OU0",
    "outputId": "064ac6e5-c643-4c6d-a914-44c0e4537660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_160 (Model) (None, 5, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "U0TBygst-B5N",
    "outputId": "5385d17d-16a2-4c03-8d06-8d0fe4590ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.7478 \n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 15450s 24s/step - loss: 0.1273 - accuracy: 0.7478 - val_loss: 0.0627 - val_accuracy: 0.8850\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9052\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 139ms/step - loss: 0.0523 - accuracy: 0.9052 - val_loss: 0.0496 - val_accuracy: 0.9095\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9264\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 92s 140ms/step - loss: 0.0411 - accuracy: 0.9264 - val_loss: 0.0448 - val_accuracy: 0.9191\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9362\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 140ms/step - loss: 0.0351 - accuracy: 0.9362 - val_loss: 0.0423 - val_accuracy: 0.9231\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9460\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 138ms/step - loss: 0.0308 - accuracy: 0.9460 - val_loss: 0.0408 - val_accuracy: 0.9264\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9530\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 140ms/step - loss: 0.0273 - accuracy: 0.9530 - val_loss: 0.0398 - val_accuracy: 0.9271\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9579\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 90s 138ms/step - loss: 0.0249 - accuracy: 0.9579 - val_loss: 0.0391 - val_accuracy: 0.9270\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9626\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 139ms/step - loss: 0.0225 - accuracy: 0.9626 - val_loss: 0.0382 - val_accuracy: 0.9289\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9677\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 91s 139ms/step - loss: 0.0204 - accuracy: 0.9677 - val_loss: 0.0376 - val_accuracy: 0.9298\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9706\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "654/654 [==============================] - 92s 141ms/step - loss: 0.0190 - accuracy: 0.9706 - val_loss: 0.0374 - val_accuracy: 0.9321\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // 32,\n",
    "    epochs=10,\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgMaPJgY-rcC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "mobilenet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
